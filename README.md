# Transporter

> Event-driven multi-cluster Kubernetes management for restricted environments

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Go Version](https://img.shields.io/badge/Go-1.25+-00ADD8?logo=go)](https://golang.org)
[![Status](https://img.shields.io/badge/Status-MVP%20Complete-brightgreen)]()

## What is Transporter?

Transporter is a lightweight, event-driven system that enables platform teams to manage Kubernetes resources across multiple clusters from a centralized control plane. It's designed for environments where direct cluster API access is restricted (air-gapped clusters, strict security policies, network isolation).

### Key Features

- **ðŸ”„ Reverse Connection Model** - Agents connect outbound to control plane (works behind firewalls)
- **âš¡ Event-Driven** - Real-time execution, not polling loops
- **ðŸª¶ Lightweight** - Minimal agent footprint (< 100MB memory)
- **ðŸ”’ Secure by Default** - mTLS authentication for all connections
- **ðŸ“Š Observable** - Built-in metrics, logging, and status tracking
- **ðŸŽ¯ Generic** - Extensible beyond K8s resources (scripts, policies)

## Architecture

### High-Level Overview

```
                    Event Producers
                         â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚            â”‚            â”‚
         HTTP API    Memphis      (Other)
            â”‚         Queue          â”‚
            â”‚            â”‚            â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Control Plane Cluster                â”‚
        â”‚                                         â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
        â”‚  â”‚ Memphis*     â”‚    â”‚   Redis      â”‚ â”‚
        â”‚  â”‚ (Optional)   â”‚    â”‚   (State)    â”‚ â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
        â”‚         â”‚                   â”‚          â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â” â”‚
        â”‚  â”‚     Control Plane (CP)           â”‚ â”‚
        â”‚  â”‚  - Event Router                  â”‚ â”‚
        â”‚  â”‚  - Agent Registry                â”‚ â”‚
        â”‚  â”‚  - WebSocket Server (0.0.0.0)    â”‚ â”‚
        â”‚  â”‚  - HTTP /events endpoint         â”‚ â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â”‚ Outbound WebSocket Connections
                          â”‚ (Agents initiate connections)
                          â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                â”‚                â”‚
         â”‚                â”‚                â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Cluster 1  â”‚ â”‚   Cluster 2  â”‚ â”‚  Cluster N   â”‚
    â”‚              â”‚ â”‚              â”‚ â”‚              â”‚
    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
    â”‚ â”‚  Agent   â”‚ â”‚ â”‚ â”‚  Agent   â”‚ â”‚ â”‚ â”‚  Agent   â”‚ â”‚
    â”‚ â”‚   (DP)   â”‚ â”‚ â”‚ â”‚   (DP)   â”‚ â”‚ â”‚ â”‚   (DP)   â”‚ â”‚
    â”‚ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â”‚
    â”‚      â”‚       â”‚ â”‚      â”‚       â”‚ â”‚      â”‚       â”‚
    â”‚      â–¼       â”‚ â”‚      â–¼       â”‚ â”‚      â–¼       â”‚
    â”‚  K8s API    â”‚ â”‚  K8s API    â”‚ â”‚  K8s API    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Architectural Principles

**1. Reverse Connection Model**
- Agents connect TO Control Plane (not the other way)
- Works in firewalled/air-gapped environments
- No inbound access needed to agent clusters

**2. Event Distribution Modes**
- **HTTP Mode**: Direct event submission to CP (testing/dev)
- **Memphis Mode**: Queue-based distribution (production)

**3. Components**

| Component | Purpose | Deployment |
|-----------|---------|------------|
| **Control Plane (CP)** | Routes events, manages agent connections | Dedicated cluster |
| **Data Plane Agents** | Execute operations in target K8s clusters | Each managed cluster |
| **Memphis** | Message queue for event distribution (optional) | CP cluster |
| **Redis** | State store for events, agents, audit logs | CP cluster |
| **Event Producer** | CLI tool to create/submit events | Anywhere with network access |

**4. Communication Flow**
```
Event Created â†’ CP Receives â†’ CP Routes â†’ Agent Executes â†’ Status Reports Back
```

## Use Cases

- **Multi-Cluster Deployments** - Deploy namespaces, CRDs, and resources across many clusters
- **Platform Engineering** - Build internal developer platforms with centralized control
- **Air-Gapped Environments** - Manage clusters without direct API access
- **Compliance & Governance** - Centralized audit trail for all cluster operations

## Project Status

ðŸŽ‰ **MVP Complete and Tested!** - All core functionality working end-to-end

### Test Results (2026-02-10)

Successfully tested complete event flow in **multi-cluster setup**:

âœ… **Event sent** â†’ CP (cp-cluster) â†’ Agent (agent-cluster) â†’ **Namespace created!**

```bash
# Send event via HTTP to CP in cp-cluster
$ curl -X POST http://localhost:30080/events -H "Content-Type: application/json" -d '{...}'
{"event_id":"test-event-1770722316","message":"Event routed to agent","status":"accepted"}

# Verify namespace created in agent-cluster (different cluster!)
$ kubectl config use-context kind-agent-cluster
$ kubectl get namespace test-namespace-1770722316
NAME                        STATUS   AGE
test-namespace-1770722316   Active   10s
```

**Multi-phase execution observed:**
- âœ… Event received by agent (cross-cluster WebSocket)
- âœ… Manifest validated
- âœ… Resources applied to cluster
- âœ… Verification complete
- âœ… Status reported back to CP

**Cross-Cluster Communication:**
- âœ… CP in `cp-cluster` exposed via NodePort (30080)
- âœ… Agent in `agent-cluster` connected via Docker network
- âœ… WebSocket connection: ws://172.18.0.2:30080/ws
- âœ… Event successfully routed and executed across clusters

See [TEST-SUCCESS.md](./TEST-SUCCESS.md) for complete test report.

### What's Working

- âœ… Control Plane with event routing and agent management
- âœ… Data Plane agents executing K8s operations
- âœ… WebSocket communication with heartbeats
- âœ… HTTP `/events` endpoint for direct event submission
- âœ… Memphis queue integration (optional)
- âœ… Redis state persistence and audit logging
- âœ… Event producer CLI (HTTP and Memphis modes)
- âœ… Helm charts for easy deployment
- âœ… Multi-phase status reporting
- âœ… Distroless container images (42.1 MB)

### Ready for Production Hardening

Core platform is functional. Next steps:
- mTLS authentication for agents
- Prometheus metrics export
- Web UI dashboard
- Performance benchmarking

See [CONTEXT.md](./CONTEXT.md) for detailed development history.

## Quick Start

### 1. Deploy to kind Cluster

```bash
# Create kind cluster (if not exists)
kind create cluster

# Build and deploy everything (Control Plane + Agent)
make all

# Check deployment status
kubectl get pods -n transporter-system
```

Expected output:
```
NAME                                 READY   STATUS    RESTARTS   AGE
transporter-agent-xxxxx              1/1     Running   0          1m
transporter-cp-xxxxx                 1/1     Running   0          1m
transporter-cp-redis-master-0        1/1     Running   0          1m
```

### 2. Port-forward Control Plane (for local testing)

```bash
kubectl port-forward -n transporter-system svc/transporter-cp 8080:8080
```

### 3. Send an Event

```bash
# Build event producer
make build-producer

# Create namespace via event (HTTP mode)
./bin/event-producer k8s \
  --agent kind-agent-1 \
  --manifest examples/manifests/namespace.yaml \
  --cp-url http://localhost:8080 \
  --mode http

# Verify namespace created
kubectl get namespace transporter-test
```

Expected output:
```
ðŸ“¤ Publishing event xxx to agent kind-agent-1
ðŸ”Œ Sending event to Control Plane...
âœ… Event accepted by Control Plane
âœ… Event published successfully!

NAME               STATUS   AGE
transporter-test   Active   5s
```

### 4. Monitor Event Execution

```bash
# Watch agent logs
kubectl logs -n transporter-system -l app.kubernetes.io/name=transporter-agent -f

# Check CP logs
kubectl logs -n transporter-system -l app.kubernetes.io/name=transporter-cp -f

# View metrics
curl http://localhost:8080/metrics | jq
```

See [examples/README.md](./examples/README.md) for more event producer usage examples.

## Multi-Cluster Setup (Production-like)

For production-like testing, deploy Control Plane and Agents in separate kind clusters. This validates cross-cluster communication and simulates real-world deployments.

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ cp-cluster (Control Plane Cluster)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Pods:                                                   â”‚
â”‚   â”œâ”€â”€ transporter-cp              [1/1 Running]        â”‚
â”‚   â””â”€â”€ transporter-cp-redis-master [1/1 Running]        â”‚
â”‚                                                          â”‚
â”‚ Services:                                               â”‚
â”‚   â”œâ”€â”€ transporter-cp               NodePort 8080:30080 â”‚
â”‚   â””â”€â”€ transporter-cp-redis-master  ClusterIP 6379      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â”‚ WebSocket: ws://172.18.0.2:30080/ws
                     â”‚ (Cross-cluster connection)
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ agent-cluster (Data Plane Cluster)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Pods:                                                   â”‚
â”‚   â””â”€â”€ transporter-agent           [1/1 Running]        â”‚
â”‚                                                          â”‚
â”‚ Agent Details:                                          â”‚
â”‚   â”œâ”€â”€ ID: agent-cluster-agent-1                        â”‚
â”‚   â”œâ”€â”€ Connects to CP external endpoint (NodePort)      â”‚
â”‚   â””â”€â”€ Executes K8s operations in this cluster          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Setup Steps

#### 1. Create Two Kind Clusters

```bash
# Create CP cluster with NodePort mappings
cat > cp-cluster-config.yaml <<EOF
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
name: cp-cluster
nodes:
  - role: control-plane
    extraPortMappings:
      - containerPort: 30080  # CP WebSocket
        hostPort: 30080
        protocol: TCP
      - containerPort: 30090  # Memphis UI (optional)
        hostPort: 30090
        protocol: TCP
      - containerPort: 30666  # Memphis broker (optional)
        hostPort: 30666
        protocol: TCP
EOF

kind create cluster --config cp-cluster-config.yaml

# Create Agent cluster
cat > agent-cluster-config.yaml <<EOF
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
name: agent-cluster
nodes:
  - role: control-plane
EOF

kind create cluster --config agent-cluster-config.yaml
```

#### 2. Deploy Control Plane to cp-cluster

```bash
# Switch to CP cluster context
kubectl config use-context kind-cp-cluster

# Build and load image (if not using registry)
make build
make podman-build
kind load docker-image localhost/transporter:0.1.0 --name cp-cluster

# Deploy CP with NodePort service
helm install transporter-cp deploy/helm/transporter-cp \
  --namespace transporter-system \
  --create-namespace \
  --set cp.memphis.enabled=false \
  --set service.type=NodePort \
  --set service.nodePort=30080

# Wait for CP to be ready
kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=transporter-cp \
  -n transporter-system --timeout=120s

# Get CP external IP (Docker network IP)
CP_IP=$(docker inspect cp-cluster-control-plane \
  --format '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}')
echo "CP accessible at: ws://${CP_IP}:30080/ws"
```

#### 3. Deploy Agent to agent-cluster

```bash
# Switch to Agent cluster context
kubectl config use-context kind-agent-cluster

# Load same image into agent cluster
kind load docker-image localhost/transporter:0.1.0 --name agent-cluster

# Get CP external endpoint
CP_IP=$(docker inspect cp-cluster-control-plane \
  --format '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}')

# Deploy Agent pointing to CP external endpoint
helm install transporter-agent deploy/helm/transporter-agent \
  --namespace transporter-system \
  --create-namespace \
  --set agent.id=agent-cluster-agent-1 \
  --set agent.cluster=agent-cluster \
  --set agent.cpURL=ws://${CP_IP}:30080/ws

# Wait for agent to be ready
kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=transporter-agent \
  -n transporter-system --timeout=120s
```

#### 4. Verify Cross-Cluster Connectivity

```bash
# Check CP health (from host machine)
curl http://localhost:30080/health
# Expected: {"agent_count":1,"status":"healthy","version":"0.1.0"}

# Check CP logs for agent connection
kubectl config use-context kind-cp-cluster
kubectl logs -n transporter-system -l app.kubernetes.io/name=transporter-cp | grep "Agent connected"
# Expected: âœ… Agent connected | agent_id=agent-cluster-agent-1 | cluster=agent-cluster

# Check Agent logs
kubectl config use-context kind-agent-cluster
kubectl logs -n transporter-system -l app.kubernetes.io/name=transporter-agent
# Expected: âœ… Connected to Control Plane
#           âœ… Agent registered successfully
```

#### 5. Test Event Flow Across Clusters

```bash
# Send event via HTTP to CP (from host machine)
curl -X POST http://localhost:30080/events \
  -H "Content-Type: application/json" \
  -d "{
    \"id\": \"test-event-$(date +%s)\",
    \"type\": \"k8s_resource\",
    \"target_agent\": \"agent-cluster-agent-1\",
    \"payload\": {
      \"manifests\": [\"apiVersion: v1\\nkind: Namespace\\nmetadata:\\n  name: test-namespace-$(date +%s)\\n  labels:\\n    created-by: transporter-test\"]
    },
    \"created_at\": \"$(date -u +\"%Y-%m-%dT%H:%M:%SZ\")\",
    \"ttl\": 3600000000000,
    \"created_by\": \"manual-test\",
    \"priority\": 0
  }"

# Verify namespace created in agent-cluster
kubectl config use-context kind-agent-cluster
kubectl get namespaces | grep test-namespace
# Expected: test-namespace-XXXXX   Active   10s

# View CP logs for routing
kubectl config use-context kind-cp-cluster
kubectl logs -n transporter-system -l app.kubernetes.io/name=transporter-cp --tail=20
# Expected: ðŸ“¨ Received event via HTTP
#           ðŸ“¤ Event routed to agent
#           ðŸ“Š Status updates (received â†’ validating â†’ applying â†’ completed)

# View Agent logs for execution
kubectl config use-context kind-agent-cluster
kubectl logs -n transporter-system -l app.kubernetes.io/name=transporter-agent --tail=20
# Expected: ðŸ“¥ Received event
#           âœ… Event completed successfully
```

### Key Points

1. **NodePort Exposure**: CP service exposed via NodePort (30080) for external access
2. **Docker Network**: Both clusters share Docker network, CP accessible via container IP
3. **Cross-Cluster WebSocket**: Agent connects from agent-cluster to CP in cp-cluster
4. **Production Pattern**: This setup mimics production where CP and agents are in different networks/clusters

### Cleanup

```bash
# Delete both clusters
kind delete cluster --name cp-cluster
kind delete cluster --name agent-cluster

# Or delete specific cluster
kind delete cluster --name agent-cluster
```

See [examples/README.md](./examples/README.md) for more event producer usage examples.

## How It Works

### Event Flow

1. **Event Creation**: Use the event producer CLI to create an event from K8s manifests
2. **Event Submission**: Event sent to CP via HTTP POST (`/events`) or Memphis queue
3. **Event Routing**: CP routes event to target agent by agent ID
4. **Agent Execution**: Agent receives event and executes in multiple phases:
   - Received â†’ Validating â†’ Applying â†’ Verifying â†’ Completed
5. **Status Reporting**: Agent sends status updates back to CP at each phase
6. **State Persistence**: CP stores event status and audit logs in Redis

### Agent Connection

- Agents initiate outbound WebSocket connection to CP (reverse connection model)
- Connection maintained with periodic heartbeats (10s interval)
- Agents register with metadata (cluster name, region, capabilities)
- CP tracks connected agents and routes events accordingly

### Event Producer Modes

**HTTP Mode** (for testing/development):
```bash
./bin/event-producer k8s --mode http --cp-url http://localhost:8080 ...
```
Sends events directly to CP HTTP endpoint.

**Memphis Mode** (for production):
```bash
./bin/event-producer k8s --mode memphis --memphis-host localhost:6666 ...
```
Publishes events to Memphis queue for reliable distribution.

## Documentation

- **[TEST-SUCCESS.md](./TEST-SUCCESS.md)** - Complete test report with results
- **[DEPLOYMENT.md](./DEPLOYMENT.md)** - Full deployment guide for kind cluster
- **[examples/README.md](./examples/README.md)** - Event producer usage and examples
- **[CONTEXT.md](./CONTEXT.md)** - Development history, decisions, and current state

## Development

### Prerequisites

- Go 1.25+
- Podman or Docker
- kind (Kubernetes in Docker)
- kubectl
- Helm 3.x

### Build from Source

```bash
# Clone the repository
git clone https://github.com/suyog1pathak/transporter.git
cd transporter

# Install dependencies
go mod download

# Build unified binary (cp + agent in one)
make build

# Build with podman (distroless, multi-arch)
make podman-build

# Build event producer CLI
make build-producer
```

### Local Development

```bash
# Run Control Plane locally (requires Redis, Memphis optional)
./bin/transporter cp \
  --redis-addr localhost:6379 \
  --memphis-enabled=false \
  --debug

# Run Agent locally (connects to CP)
./bin/transporter agent \
  --agent-id local-agent \
  --cluster-name local-cluster \
  --cp-url ws://localhost:8080/ws \
  --debug

# Send test event (HTTP mode, no Memphis needed)
./bin/event-producer k8s \
  --agent local-agent \
  --manifest examples/manifests/namespace.yaml \
  --cp-url http://localhost:8080 \
  --mode http
```

### Running Tests

```bash
# Unit tests
go test ./...

# End-to-end test on kind
make all
kubectl port-forward -n transporter-system svc/transporter-cp 8080:8080 &
./bin/event-producer k8s --agent kind-agent-1 --manifest examples/manifests/namespace.yaml --mode http
kubectl get namespace transporter-test
```

## Roadmap

### Phase 1: MVP âœ… **COMPLETE**
- âœ… WebSocket communication (client + server)
- âœ… Agent registration and identity management
- âœ… Event routing to target agents
- âœ… Memphis queue integration (optional)
- âœ… Redis state persistence
- âœ… K8s resource operations (apply YAML manifests)
- âœ… Multi-phase status reporting
- âœ… Event expiration and TTL handling
- âœ… Heartbeat mechanism (10s interval)
- âœ… Helm charts for deployment
- âœ… Event producer CLI tool (HTTP + Memphis modes)
- âœ… Distroless container images (42.1 MB)
- âœ… HTTP `/events` endpoint for direct submission
- âœ… **End-to-end testing on kind cluster - ALL PASSING**

### Phase 2: Production Hardening
- mTLS authentication for agents
- Prometheus metrics export
- Web UI dashboard for event status
- Advanced retry logic with exponential backoff
- Event priority queuing
- Performance benchmarking

### Phase 3: Extended Features
- Custom script execution on agents
- Policy validation and enforcement
- Agent auto-upgrade mechanism
- High availability for Control Plane
- Security audit
- Multi-tenancy support

See [CONTEXT.md](./CONTEXT.md) for detailed roadmap and decisions.

## Contributing

Contributions are welcome! This project is in early development, so expect rapid changes.

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## License

MIT License - see [LICENSE](./LICENSE) for details

## Technical Details

- **Language**: Go 1.25
- **Container Base**: Google Distroless (static-debian12:nonroot)
- **Image Size**: 42.1 MB (37.2 MB binary)
- **Build Tool**: Podman with multi-arch support
- **Logging**: Structured logging with slog
- **State Store**: Redis (in-memory)
- **Message Queue**: Memphis (optional, NATS-based)
- **Protocol**: WebSocket for agent connections, HTTP for events
- **Deployment**: Helm charts for Kubernetes

## Contact

- **Issues**: [GitHub Issues](https://github.com/suyog1pathak/transporter/issues)
- **Repository**: [github.com/suyog1pathak/transporter](https://github.com/suyog1pathak/transporter)

---

**Built with â¤ï¸ for Platform Engineers and DevOps teams**

**Status**: MVP Complete - Multi-Cluster Tested | **Version**: 0.1.0 | **Last Updated**: 2026-02-10
